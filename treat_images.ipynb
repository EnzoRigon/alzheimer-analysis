{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af5995f7",
   "metadata": {},
   "source": [
    "## Tratamento do Dataset\n",
    "\n",
    "O dataset escolhido apresenta uma grande disparidade entre as categorias, então precisamos balancear isso. Para o nosso estudo de caso, vamos reduzir as categorias que possuem mais de 7000 exemplos para 7000, e realizar data augmentation nas que possuem menos exemplos.\n",
    "\n",
    "![Quantidade de dados](imgs/qtd_dados.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ccc97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta 'Mild Dementia' tem 5002 arquivos, nada a fazer.\n",
      "Pasta 'Very mild Dementia' reduzida para 7000 arquivos.\n",
      "Pasta 'Moderate Dementia' tem 488 arquivos, nada a fazer.\n",
      "Pasta 'Non Demented' reduzida para 7000 arquivos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "main_dir = 'Data'\n",
    "\n",
    "for folder in os.listdir(main_dir):\n",
    "    folder_path = os.path.join(main_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        if len(files) > 7000:\n",
    "            keep_files = set(random.sample(files, 7000))\n",
    "            for f in files:\n",
    "                if f not in keep_files:\n",
    "                    os.remove(os.path.join(folder_path, f))\n",
    "            print(f\"Pasta '{folder}' reduzida para 7000 arquivos.\")\n",
    "        else:\n",
    "            print(f\"Pasta '{folder}' tem {len(files)} arquivos, nada a fazer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2ed0e1",
   "metadata": {},
   "source": [
    "## Verificando o Tamanho das Imagens\n",
    "\n",
    "Antes de prosseguir, vamos analisar as dimensões das imagens do dataset para identificar possíveis variações de tamanho. Caso existam diferentes resoluções, será necessário realizar um redimensionamento (reshape) para padronizar todas as imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d31c6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pasta: Mild Dementia\n",
      "OAS1_0137_MR1_mpr-3_139.jpg: (496, 248)\n",
      "\n",
      "Pasta: Very mild Dementia\n",
      "OAS1_0023_MR1_mpr-3_127.jpg: (496, 248)\n",
      "\n",
      "Pasta: Moderate Dementia\n",
      "OAS1_0308_MR1_mpr-1_125.jpg: (496, 248)\n",
      "\n",
      "Pasta: Non Demented\n",
      "OAS1_0234_MR1_mpr-4_136.jpg: (496, 248)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for folder in os.listdir(main_dir):\n",
    "    folder_path = os.path.join(main_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        print(f\"\\nPasta: {folder}\")\n",
    "        tamanhos_vistos = set()\n",
    "        for f in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, f)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        if img.size not in tamanhos_vistos:\n",
    "                            print(f\"{f}: {img.size}\") \n",
    "                            tamanhos_vistos.add(img.size)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao abrir {f}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69e2157",
   "metadata": {},
   "source": [
    "## Começando o Pré-processamento\n",
    "\n",
    "Como primeiro passo do pré-processamento, vamos converter todas as imagens do dataset para preto e branco. Isso garante uniformidade nos dados e facilita o processamento nas etapas seguintes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fd9cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in os.listdir(main_dir):\n",
    "    folder_path = os.path.join(main_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for f in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, f)\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        img = img.convert('L')  # Converte para preto e branco\n",
    "                        img.save(file_path)     # Sobrescreve a imagem original\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao converter {f}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc98193",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Agora, vamos aplicar técnicas de data augmentation para gerar mais exemplos nas classes com menos imagens, ajudando a balancear o dataset e melhorar a capacidade de generalização do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57b4381c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta 'Mild Dementia' tem 5002 arquivos. Fazendo data augmentation...\n",
      "Pasta 'Mild Dementia' aumentada para 7000 arquivos.\n",
      "Pasta 'Very mild Dementia' já tem 7000 arquivos ou mais.\n",
      "Pasta 'Moderate Dementia' tem 488 arquivos. Fazendo data augmentation...\n",
      "Pasta 'Moderate Dementia' aumentada para 7000 arquivos.\n",
      "Pasta 'Non Demented' já tem 7000 arquivos ou mais.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "main_dir = 'Data'\n",
    "target_size = (248, 496)  # TensorFlow usa (altura, largura)\n",
    "target_count = 7000\n",
    "\n",
    "# Defina as transformações de data augmentation\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.2),\n",
    "    tf.keras.layers.RandomZoom(0.1),\n",
    "])\n",
    "\n",
    "for folder in os.listdir(main_dir):\n",
    "    folder_path = os.path.join(main_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        n_files = len(files)\n",
    "        if n_files < target_count:\n",
    "            print(f\"Pasta '{folder}' tem {n_files} arquivos. Fazendo data augmentation...\")\n",
    "            i = 0\n",
    "            while n_files + i < target_count:\n",
    "                f = random.choice(files)\n",
    "                file_path = os.path.join(folder_path, f)\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        # Converte para preto e branco\n",
    "                        img = img.convert('L')\n",
    "                        # Redimensiona\n",
    "                        img = img.resize(target_size[::-1])  # PIL usa (largura, altura)\n",
    "                        # Converte para array e adiciona canal extra para TensorFlow\n",
    "                        arr = np.array(img)[..., np.newaxis]\n",
    "                        arr = arr / 255.0  # Normaliza\n",
    "                        arr = np.expand_dims(arr, 0)  # Adiciona batch dimension\n",
    "                        # Aplica data augmentation\n",
    "                        aug_img = data_augmentation(arr, training=True)\n",
    "                        aug_img = tf.squeeze(aug_img).numpy()\n",
    "                        aug_img = (aug_img * 255).astype(np.uint8)\n",
    "                        # Remove batch dimension e canal extra\n",
    "                        aug_img = np.squeeze(aug_img)\n",
    "                        # Salva imagem aumentada\n",
    "                        aug_pil = Image.fromarray(aug_img, mode='L')\n",
    "                        new_name = f\"aug_{i}_{f}\"\n",
    "                        aug_pil.save(os.path.join(folder_path, new_name))\n",
    "                        i += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"Erro ao abrir {f}: {e}\")\n",
    "            print(f\"Pasta '{folder}' aumentada para {target_count} arquivos.\")\n",
    "        else:\n",
    "            print(f\"Pasta '{folder}' já tem {n_files} arquivos ou mais.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b88417",
   "metadata": {},
   "source": [
    "## Verificação Final\n",
    "\n",
    "Agora, vamos conferir se todas as pastas possuem a quantidade correta de imagens, se todas estão em preto e branco e se os tamanhos das imagens estão padronizados. Essa verificação garante que o dataset está pronto para ser utilizado nas próximas etapas do processamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65d668e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pasta 'Mild Dementia': 7000 imagens\n",
      "Tamanhos encontrados: {(496, 248)}\n",
      "Todas as imagens estão em preto e branco.\n",
      "\n",
      "Pasta 'Very mild Dementia': 7000 imagens\n",
      "Tamanhos encontrados: {(496, 248)}\n",
      "Todas as imagens estão em preto e branco.\n",
      "\n",
      "Pasta 'Moderate Dementia': 7000 imagens\n",
      "Tamanhos encontrados: {(496, 248)}\n",
      "Todas as imagens estão em preto e branco.\n",
      "\n",
      "Pasta 'Non Demented': 7000 imagens\n",
      "Tamanhos encontrados: {(496, 248)}\n",
      "Todas as imagens estão em preto e branco.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for folder in os.listdir(main_dir):\n",
    "    folder_path = os.path.join(main_dir, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        files = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "        tamanhos_vistos = set()\n",
    "        coloridas = 0\n",
    "        for f in files:\n",
    "            file_path = os.path.join(folder_path, f)\n",
    "            try:\n",
    "                with Image.open(file_path) as img:\n",
    "                    tamanhos_vistos.add(img.size)\n",
    "                    if img.mode != 'L':\n",
    "                        coloridas += 1\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao abrir {f}: {e}\")\n",
    "        print(f\"Pasta '{folder}': {len(files)} imagens\")\n",
    "        print(f\"Tamanhos encontrados: {tamanhos_vistos}\")\n",
    "        if coloridas == 0:\n",
    "            print(\"Todas as imagens estão em preto e branco.\\n\")\n",
    "        else:\n",
    "            print(f\"{coloridas} imagens NÃO estão em preto e branco.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
